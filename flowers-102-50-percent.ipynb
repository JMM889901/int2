{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-05-07T13:25:56.049379Z",
     "iopub.execute_input": "2023-05-07T13:25:56.051573Z",
     "iopub.status.idle": "2023-05-07T13:26:01.117354Z",
     "shell.execute_reply.started": "2023-05-07T13:25:56.051532Z",
     "shell.execute_reply": "2023-05-07T13:26:01.116426Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "input_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAdjustSharpness(2),\n",
    "    transforms.RandomEqualize(),\n",
    "    transforms.ColorJitter(0.5, 0.5, 0.5),\n",
    "    transforms.RandomPosterize(6),\n",
    "    transforms.RandomResizedCrop((400, 400)),\n",
    "    transforms.Resize((256, 256)),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "output_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "training_data = datasets.Flowers102(root=\"data\", split=\"train\", download=False, transform=input_transform)\n",
    "validation_data = datasets.Flowers102(root=\"data\", split=\"val\", download=False, transform=output_transform)\n",
    "test_data = datasets.Flowers102(root=\"data\", split=\"test\", download=False, transform=output_transform)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T13:26:16.567598Z",
     "iopub.execute_input": "2023-05-07T13:26:16.567949Z",
     "iopub.status.idle": "2023-05-07T13:26:16.641848Z",
     "shell.execute_reply.started": "2023-05-07T13:26:16.567923Z",
     "shell.execute_reply": "2023-05-07T13:26:16.640987Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(validation_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T13:26:24.196888Z",
     "iopub.execute_input": "2023-05-07T13:26:24.197260Z",
     "iopub.status.idle": "2023-05-07T13:26:24.205098Z",
     "shell.execute_reply.started": "2023-05-07T13:26:24.197231Z",
     "shell.execute_reply": "2023-05-07T13:26:24.204143Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class FlowersModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(64)\n",
    "        self.dropout2d = nn.Dropout2d(0.2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(64 * 32 * 32, 256)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(256)\n",
    "        self.final = nn.Linear(256, 102)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.output = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.relu,\n",
    "            self.batch_norm1,\n",
    "            self.pool2,\n",
    "            self.conv2,\n",
    "            self.relu,\n",
    "            self.batch_norm2,\n",
    "            self.dropout2d,\n",
    "            self.pool2,\n",
    "            self.conv3,\n",
    "            self.relu,\n",
    "            self.batch_norm3,\n",
    "            self.pool2,\n",
    "            self.flatten,\n",
    "            self.dropout,\n",
    "            self.linear,\n",
    "            self.relu,\n",
    "            self.batch_norm4,\n",
    "            self.dropout,\n",
    "            self.final,\n",
    "            self.softmax\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(x)\n",
    "\n",
    "    def get_first_conv_output(self, x):\n",
    "        return self.relu(self.conv1(x))\n",
    "\n",
    "    def get_second_conv_output(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        return self.relu(self.conv2(self.pool1(x)))\n",
    "\n",
    "    def get_third_conv_output(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(self.pool1(x)))\n",
    "        return self.relu(self.conv3(self.pool2(x)))\n",
    "\n",
    "model = FlowersModel().to(device)\n",
    "model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T13:36:54.932218Z",
     "iopub.execute_input": "2023-05-07T13:36:54.932618Z",
     "iopub.status.idle": "2023-05-07T13:36:55.249526Z",
     "shell.execute_reply.started": "2023-05-07T13:36:54.932588Z",
     "shell.execute_reply": "2023-05-07T13:36:55.248480Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "execution_count": 17,
     "output_type": "execute_result",
     "data": {
      "text/plain": "FlowersModel(\n  (relu): LeakyReLU(negative_slope=0.01)\n  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (batch_norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (batch_norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout2d): Dropout2d(p=0.2, inplace=False)\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear): Linear(in_features=65536, out_features=256, bias=True)\n  (batch_norm4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (final): Linear(in_features=256, out_features=102, bias=True)\n  (softmax): LogSoftmax(dim=1)\n  (output): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout2d(p=0.2, inplace=False)\n    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (10): LeakyReLU(negative_slope=0.01)\n    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (13): Flatten(start_dim=1, end_dim=-1)\n    (14): Dropout(p=0.5, inplace=False)\n    (15): Linear(in_features=65536, out_features=256, bias=True)\n    (16): LeakyReLU(negative_slope=0.01)\n    (17): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (18): Dropout(p=0.5, inplace=False)\n    (19): Linear(in_features=256, out_features=102, bias=True)\n    (20): LogSoftmax(dim=1)\n  )\n)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "learning_rate = 0.001\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimiser = torch.optim.AdamW(model.parameters(), learning_rate)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T13:38:26.449245Z",
     "iopub.execute_input": "2023-05-07T13:38:26.449624Z",
     "iopub.status.idle": "2023-05-07T13:38:26.457012Z",
     "shell.execute_reply.started": "2023-05-07T13:38:26.449591Z",
     "shell.execute_reply": "2023-05-07T13:38:26.456130Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(dataloader: DataLoader, training_model: nn.Module, optim: torch.optim.Optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    training_model.train()\n",
    "    for batch_no, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optim.zero_grad()\n",
    "        pred = training_model(X)\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if batch_no % 4 == 0:\n",
    "            loss, current = loss.item(), (batch_no + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader:DataLoader, eval_model: nn.Module, losses: list, accuracy: list):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = eval_model(X)\n",
    "            total_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    total_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    losses.append(total_loss)\n",
    "    accuracy.append(100 * correct)\n",
    "\n",
    "    print(f\"Accuracy: {(100 * correct):>0.1f}%, Avg loss: {total_loss:>8f} \\n\")\n",
    "    return total_loss\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T13:38:28.218008Z",
     "iopub.execute_input": "2023-05-07T13:38:28.218370Z",
     "iopub.status.idle": "2023-05-07T13:38:28.229604Z",
     "shell.execute_reply.started": "2023-05-07T13:38:28.218340Z",
     "shell.execute_reply": "2023-05-07T13:38:28.228594Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(device)\n",
    "epochs = 360\n",
    "val_losses = []\n",
    "val_accuracy = []\n",
    "train_losses = []\n",
    "train_accuracy = []\n",
    "epoch_list = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 241}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, optimiser)\n",
    "    epoch_list.append(t+241)\n",
    "    print(\"Validation Error:\")\n",
    "    loss_val = test(val_dataloader, model, val_losses, val_accuracy)\n",
    "    print(\"Training Error:\")\n",
    "    loss_train = test(train_dataloader, model, train_losses, train_accuracy)\n",
    "\n",
    "print(\"Done!\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T16:18:11.980941Z",
     "iopub.execute_input": "2023-05-07T16:18:11.981359Z",
     "iopub.status.idle": "2023-05-07T17:26:04.449821Z",
     "shell.execute_reply.started": "2023-05-07T16:18:11.981327Z",
     "shell.execute_reply": "2023-05-07T17:26:04.448851Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": "cuda\nEpoch 241\n-------------------------------\nloss: 2.340311 [  128/ 1020]\nloss: 2.257232 [  640/ 1020]\nValidation Error:\nAccuracy: 49.9%, Avg loss: 2.044534 \n\nTraining Error:\nAccuracy: 52.0%, Avg loss: 1.958070 \n\nEpoch 242\n-------------------------------\nloss: 2.639326 [  128/ 1020]\nloss: 2.342116 [  640/ 1020]\nValidation Error:\nAccuracy: 49.9%, Avg loss: 2.064427 \n\nTraining Error:\nAccuracy: 51.8%, Avg loss: 2.039316 \n\nEpoch 243\n-------------------------------\nloss: 2.229205 [  128/ 1020]\nloss: 2.257051 [  640/ 1020]\nValidation Error:\nAccuracy: 50.2%, Avg loss: 2.041220 \n\nTraining Error:\nAccuracy: 50.2%, Avg loss: 2.029491 \n\nEpoch 244\n-------------------------------\nloss: 2.468345 [  128/ 1020]\nloss: 2.511885 [  640/ 1020]\nValidation Error:\nAccuracy: 49.1%, Avg loss: 2.036911 \n\nTraining Error:\nAccuracy: 54.5%, Avg loss: 1.926754 \n\nEpoch 245\n-------------------------------\nloss: 2.298992 [  128/ 1020]\nloss: 2.640109 [  640/ 1020]\nValidation Error:\nAccuracy: 48.4%, Avg loss: 2.034419 \n\nTraining Error:\nAccuracy: 49.5%, Avg loss: 2.069053 \n\nEpoch 246\n-------------------------------\nloss: 2.524468 [  128/ 1020]\nloss: 2.476554 [  640/ 1020]\nValidation Error:\nAccuracy: 49.6%, Avg loss: 2.087205 \n\nTraining Error:\nAccuracy: 49.6%, Avg loss: 2.059415 \n\nEpoch 247\n-------------------------------\nloss: 2.686026 [  128/ 1020]\nloss: 2.368818 [  640/ 1020]\nValidation Error:\nAccuracy: 50.2%, Avg loss: 2.052306 \n\nTraining Error:\nAccuracy: 52.0%, Avg loss: 2.061966 \n\nEpoch 248\n-------------------------------\nloss: 2.404797 [  128/ 1020]\nloss: 2.370436 [  640/ 1020]\nValidation Error:\nAccuracy: 51.2%, Avg loss: 2.023686 \n\nTraining Error:\nAccuracy: 52.7%, Avg loss: 1.974198 \n\nEpoch 249\n-------------------------------\nloss: 2.731587 [  128/ 1020]\nloss: 2.381268 [  640/ 1020]\nValidation Error:\nAccuracy: 49.8%, Avg loss: 2.042760 \n\nTraining Error:\nAccuracy: 50.7%, Avg loss: 2.003490 \n\nEpoch 250\n-------------------------------\nloss: 2.458357 [  128/ 1020]\nloss: 2.569134 [  640/ 1020]\nValidation Error:\nAccuracy: 50.4%, Avg loss: 2.031798 \n\nTraining Error:\nAccuracy: 54.5%, Avg loss: 1.948468 \n\nEpoch 251\n-------------------------------\nloss: 2.620432 [  128/ 1020]\nloss: 2.598445 [  640/ 1020]\nValidation Error:\nAccuracy: 50.8%, Avg loss: 2.006915 \n\nTraining Error:\nAccuracy: 52.4%, Avg loss: 1.992838 \n\nEpoch 252\n-------------------------------\nloss: 2.565659 [  128/ 1020]\nloss: 2.435109 [  640/ 1020]\nValidation Error:\nAccuracy: 50.6%, Avg loss: 2.028668 \n\nTraining Error:\nAccuracy: 50.8%, Avg loss: 2.052253 \n\nEpoch 253\n-------------------------------\nloss: 2.421601 [  128/ 1020]\nloss: 2.298842 [  640/ 1020]\nValidation Error:\nAccuracy: 47.9%, Avg loss: 2.116554 \n\nTraining Error:\nAccuracy: 49.6%, Avg loss: 2.081043 \n\nEpoch 254\n-------------------------------\nloss: 2.213596 [  128/ 1020]\nloss: 2.485584 [  640/ 1020]\nValidation Error:\nAccuracy: 47.7%, Avg loss: 2.108389 \n\nTraining Error:\nAccuracy: 49.4%, Avg loss: 2.058021 \n\nEpoch 255\n-------------------------------\nloss: 2.416997 [  128/ 1020]\nloss: 2.750165 [  640/ 1020]\nValidation Error:\nAccuracy: 47.3%, Avg loss: 2.130241 \n\nTraining Error:\nAccuracy: 48.7%, Avg loss: 2.172783 \n\nEpoch 256\n-------------------------------\nloss: 2.141755 [  128/ 1020]\nloss: 2.677172 [  640/ 1020]\nValidation Error:\nAccuracy: 50.5%, Avg loss: 2.018854 \n\nTraining Error:\nAccuracy: 52.6%, Avg loss: 1.951997 \n\nEpoch 257\n-------------------------------\nloss: 2.492685 [  128/ 1020]\nloss: 2.325349 [  640/ 1020]\nValidation Error:\nAccuracy: 49.7%, Avg loss: 2.050138 \n\nTraining Error:\nAccuracy: 53.1%, Avg loss: 1.974969 \n\nEpoch 258\n-------------------------------\nloss: 2.400699 [  128/ 1020]\nloss: 2.444135 [  640/ 1020]\nValidation Error:\nAccuracy: 48.8%, Avg loss: 2.063629 \n\nTraining Error:\nAccuracy: 55.7%, Avg loss: 1.917888 \n\nEpoch 259\n-------------------------------\nloss: 2.254084 [  128/ 1020]\nloss: 2.419195 [  640/ 1020]\nValidation Error:\nAccuracy: 49.5%, Avg loss: 2.036413 \n\nTraining Error:\nAccuracy: 53.2%, Avg loss: 1.901706 \n\nEpoch 260\n-------------------------------\nloss: 2.556541 [  128/ 1020]\nloss: 2.652676 [  640/ 1020]\nValidation Error:\nAccuracy: 49.8%, Avg loss: 2.022603 \n\nTraining Error:\nAccuracy: 51.1%, Avg loss: 1.989444 \n\nEpoch 261\n-------------------------------\nloss: 2.198826 [  128/ 1020]\nloss: 2.489928 [  640/ 1020]\nValidation Error:\nAccuracy: 48.2%, Avg loss: 2.045840 \n\nTraining Error:\nAccuracy: 56.1%, Avg loss: 1.857003 \n\nEpoch 262\n-------------------------------\nloss: 2.484695 [  128/ 1020]\nloss: 2.458410 [  640/ 1020]\nValidation Error:\nAccuracy: 50.6%, Avg loss: 2.023876 \n\nTraining Error:\nAccuracy: 56.1%, Avg loss: 1.932101 \n\nEpoch 263\n-------------------------------\nloss: 2.320321 [  128/ 1020]\nloss: 2.430099 [  640/ 1020]\nValidation Error:\nAccuracy: 49.7%, Avg loss: 2.022185 \n\nTraining Error:\nAccuracy: 52.9%, Avg loss: 1.926026 \n\nEpoch 264\n-------------------------------\nloss: 2.491688 [  128/ 1020]\nloss: 2.674528 [  640/ 1020]\nValidation Error:\nAccuracy: 49.8%, Avg loss: 2.068582 \n\nTraining Error:\nAccuracy: 54.4%, Avg loss: 1.980707 \n\nEpoch 265\n-------------------------------\nloss: 2.276031 [  128/ 1020]\nloss: 2.297632 [  640/ 1020]\nValidation Error:\nAccuracy: 49.5%, Avg loss: 2.078291 \n\nTraining Error:\nAccuracy: 52.3%, Avg loss: 2.003815 \n\nEpoch 266\n-------------------------------\nloss: 2.340168 [  128/ 1020]\nloss: 2.321751 [  640/ 1020]\nValidation Error:\nAccuracy: 51.1%, Avg loss: 2.031168 \n\nTraining Error:\nAccuracy: 52.5%, Avg loss: 1.990904 \n\nEpoch 267\n-------------------------------\nloss: 2.245538 [  128/ 1020]\nloss: 2.868940 [  640/ 1020]\nValidation Error:\nAccuracy: 51.7%, Avg loss: 2.040850 \n\nTraining Error:\nAccuracy: 50.7%, Avg loss: 2.018757 \n\nEpoch 268\n-------------------------------\nloss: 2.405130 [  128/ 1020]\nloss: 2.551624 [  640/ 1020]\nValidation Error:\nAccuracy: 48.7%, Avg loss: 2.072344 \n\nTraining Error:\nAccuracy: 51.1%, Avg loss: 1.941219 \n\nEpoch 269\n-------------------------------\nloss: 2.385984 [  128/ 1020]\nloss: 2.381090 [  640/ 1020]\nValidation Error:\nAccuracy: 50.0%, Avg loss: 2.039701 \n\nTraining Error:\nAccuracy: 54.5%, Avg loss: 1.896330 \n\nEpoch 270\n-------------------------------\nloss: 2.787522 [  128/ 1020]\nloss: 2.447762 [  640/ 1020]\nValidation Error:\nAccuracy: 49.3%, Avg loss: 2.058671 \n\nTraining Error:\nAccuracy: 54.1%, Avg loss: 1.946012 \n\nEpoch 271\n-------------------------------\nloss: 2.355553 [  128/ 1020]\nloss: 2.394586 [  640/ 1020]\nValidation Error:\nAccuracy: 49.8%, Avg loss: 2.019302 \n\nTraining Error:\nAccuracy: 55.2%, Avg loss: 1.877458 \n\nEpoch 272\n-------------------------------\nloss: 2.361293 [  128/ 1020]\nloss: 2.430386 [  640/ 1020]\nValidation Error:\nAccuracy: 49.7%, Avg loss: 2.042005 \n\nTraining Error:\nAccuracy: 54.1%, Avg loss: 1.892749 \n\nEpoch 273\n-------------------------------\nloss: 2.374586 [  128/ 1020]\nloss: 2.789800 [  640/ 1020]\nValidation Error:\nAccuracy: 50.1%, Avg loss: 2.051577 \n\nTraining Error:\nAccuracy: 54.0%, Avg loss: 1.903473 \n\nEpoch 274\n-------------------------------\nloss: 2.372001 [  128/ 1020]\nloss: 2.578264 [  640/ 1020]\nValidation Error:\nAccuracy: 49.6%, Avg loss: 2.014527 \n\nTraining Error:\nAccuracy: 54.8%, Avg loss: 1.881127 \n\nEpoch 275\n-------------------------------\nloss: 2.679896 [  128/ 1020]\nloss: 2.373092 [  640/ 1020]\nValidation Error:\nAccuracy: 49.8%, Avg loss: 2.030994 \n\nTraining Error:\nAccuracy: 55.0%, Avg loss: 1.905912 \n\nEpoch 276\n-------------------------------\nloss: 2.338468 [  128/ 1020]\nloss: 2.493088 [  640/ 1020]\nValidation Error:\nAccuracy: 47.6%, Avg loss: 2.109554 \n\nTraining Error:\nAccuracy: 51.3%, Avg loss: 1.962848 \n\nEpoch 277\n-------------------------------\nloss: 2.385790 [  128/ 1020]\nloss: 2.337040 [  640/ 1020]\nValidation Error:\nAccuracy: 48.4%, Avg loss: 2.043771 \n\nTraining Error:\nAccuracy: 54.3%, Avg loss: 1.907949 \n\nEpoch 278\n-------------------------------\nloss: 2.786013 [  128/ 1020]\nloss: 2.466918 [  640/ 1020]\nValidation Error:\nAccuracy: 47.8%, Avg loss: 2.107437 \n\nTraining Error:\nAccuracy: 50.6%, Avg loss: 2.040002 \n\nEpoch 279\n-------------------------------\nloss: 2.809109 [  128/ 1020]\nloss: 2.356623 [  640/ 1020]\nValidation Error:\nAccuracy: 49.7%, Avg loss: 2.035367 \n\nTraining Error:\nAccuracy: 52.1%, Avg loss: 1.918287 \n\nEpoch 280\n-------------------------------\nloss: 2.526580 [  128/ 1020]\nloss: 2.516677 [  640/ 1020]\nValidation Error:\nAccuracy: 49.8%, Avg loss: 2.038351 \n\nTraining Error:\nAccuracy: 56.0%, Avg loss: 1.879937 \n\nEpoch 281\n-------------------------------\nloss: 2.582446 [  128/ 1020]\nloss: 2.461762 [  640/ 1020]\nValidation Error:\nAccuracy: 50.9%, Avg loss: 2.012626 \n\nTraining Error:\nAccuracy: 55.7%, Avg loss: 1.875487 \n\nEpoch 282\n-------------------------------\nloss: 2.375095 [  128/ 1020]\nloss: 2.483273 [  640/ 1020]\nValidation Error:\nAccuracy: 50.6%, Avg loss: 2.016161 \n\nTraining Error:\nAccuracy: 53.6%, Avg loss: 1.970333 \n\nEpoch 283\n-------------------------------\nloss: 2.507539 [  128/ 1020]\nloss: 2.409490 [  640/ 1020]\nValidation Error:\nAccuracy: 50.0%, Avg loss: 1.991902 \n\nTraining Error:\nAccuracy: 54.1%, Avg loss: 1.903060 \n\nEpoch 284\n-------------------------------\nloss: 2.609347 [  128/ 1020]\nloss: 2.425977 [  640/ 1020]\nValidation Error:\nAccuracy: 49.3%, Avg loss: 2.013722 \n\nTraining Error:\nAccuracy: 54.6%, Avg loss: 1.823276 \n\nEpoch 285\n-------------------------------\nloss: 2.494063 [  128/ 1020]\nloss: 2.212435 [  640/ 1020]\nValidation Error:\nAccuracy: 50.9%, Avg loss: 2.024236 \n\nTraining Error:\nAccuracy: 55.3%, Avg loss: 1.870208 \n\nEpoch 286\n-------------------------------\nloss: 2.426537 [  128/ 1020]\nloss: 2.377659 [  640/ 1020]\nValidation Error:\nAccuracy: 51.0%, Avg loss: 2.003294 \n\nTraining Error:\nAccuracy: 54.1%, Avg loss: 1.939409 \n\nEpoch 287\n-------------------------------\nloss: 2.407599 [  128/ 1020]\nloss: 2.646102 [  640/ 1020]\nValidation Error:\nAccuracy: 50.5%, Avg loss: 1.999834 \n\nTraining Error:\nAccuracy: 52.8%, Avg loss: 1.898868 \n\nEpoch 288\n-------------------------------\nloss: 2.200033 [  128/ 1020]\nloss: 2.180390 [  640/ 1020]\nValidation Error:\nAccuracy: 50.6%, Avg loss: 1.988135 \n\nTraining Error:\nAccuracy: 52.4%, Avg loss: 1.997426 \n\nEpoch 289\n-------------------------------\nloss: 2.388591 [  128/ 1020]\nloss: 2.647794 [  640/ 1020]\nValidation Error:\nAccuracy: 50.0%, Avg loss: 2.032583 \n\nTraining Error:\nAccuracy: 52.2%, Avg loss: 1.933702 \n\nEpoch 290\n-------------------------------\nloss: 2.419241 [  128/ 1020]\nloss: 2.325631 [  640/ 1020]\nValidation Error:\nAccuracy: 50.1%, Avg loss: 2.020781 \n\nTraining Error:\nAccuracy: 54.0%, Avg loss: 1.910013 \n\nEpoch 291\n-------------------------------\nloss: 2.062099 [  128/ 1020]\nloss: 2.406892 [  640/ 1020]\nValidation Error:\nAccuracy: 49.0%, Avg loss: 2.044232 \n\nTraining Error:\nAccuracy: 53.3%, Avg loss: 1.958888 \n\nEpoch 292\n-------------------------------\nloss: 2.222294 [  128/ 1020]\nloss: 2.351894 [  640/ 1020]\nValidation Error:\nAccuracy: 49.2%, Avg loss: 1.971645 \n\nTraining Error:\nAccuracy: 57.2%, Avg loss: 1.880990 \n\nEpoch 293\n-------------------------------\nloss: 2.373152 [  128/ 1020]\nloss: 2.290253 [  640/ 1020]\nValidation Error:\nAccuracy: 50.3%, Avg loss: 2.021333 \n\nTraining Error:\nAccuracy: 57.2%, Avg loss: 1.815910 \n\nEpoch 294\n-------------------------------\nloss: 2.035792 [  128/ 1020]\nloss: 2.492083 [  640/ 1020]\nValidation Error:\nAccuracy: 50.2%, Avg loss: 2.025428 \n\nTraining Error:\nAccuracy: 52.1%, Avg loss: 1.981403 \n\nEpoch 295\n-------------------------------\nloss: 2.454240 [  128/ 1020]\nloss: 2.314732 [  640/ 1020]\nValidation Error:\nAccuracy: 49.3%, Avg loss: 2.007481 \n\nTraining Error:\nAccuracy: 54.1%, Avg loss: 1.899168 \n\nEpoch 296\n-------------------------------\nloss: 2.233323 [  128/ 1020]\nloss: 2.481368 [  640/ 1020]\nValidation Error:\nAccuracy: 51.5%, Avg loss: 1.987132 \n\nTraining Error:\nAccuracy: 54.3%, Avg loss: 1.915935 \n\nEpoch 297\n-------------------------------\nloss: 2.573287 [  128/ 1020]\nloss: 2.332163 [  640/ 1020]\nValidation Error:\nAccuracy: 51.6%, Avg loss: 1.997027 \n\nTraining Error:\nAccuracy: 52.8%, Avg loss: 1.948128 \n\nEpoch 298\n-------------------------------\nloss: 2.498470 [  128/ 1020]\nloss: 2.306661 [  640/ 1020]\nValidation Error:\nAccuracy: 50.6%, Avg loss: 1.976562 \n\nTraining Error:\nAccuracy: 56.7%, Avg loss: 1.790286 \n\nEpoch 299\n-------------------------------\nloss: 2.467622 [  128/ 1020]\nloss: 2.167031 [  640/ 1020]\nValidation Error:\nAccuracy: 50.9%, Avg loss: 1.977811 \n\nTraining Error:\nAccuracy: 57.6%, Avg loss: 1.804253 \n\nEpoch 300\n-------------------------------\nloss: 2.237907 [  128/ 1020]\nloss: 2.337703 [  640/ 1020]\nValidation Error:\nAccuracy: 50.4%, Avg loss: 2.015549 \n\nTraining Error:\nAccuracy: 54.6%, Avg loss: 1.927504 \n\nEpoch 301\n-------------------------------\nloss: 2.379376 [  128/ 1020]\nloss: 2.327929 [  640/ 1020]\nValidation Error:\nAccuracy: 49.9%, Avg loss: 1.961581 \n\nTraining Error:\nAccuracy: 59.1%, Avg loss: 1.787993 \n\nEpoch 302\n-------------------------------\nloss: 1.979112 [  128/ 1020]\nloss: 2.304279 [  640/ 1020]\nValidation Error:\nAccuracy: 51.5%, Avg loss: 1.952892 \n\nTraining Error:\nAccuracy: 55.9%, Avg loss: 1.868744 \n\nEpoch 303\n-------------------------------\nloss: 2.253044 [  128/ 1020]\nloss: 2.515449 [  640/ 1020]\nValidation Error:\nAccuracy: 51.1%, Avg loss: 1.959860 \n\nTraining Error:\nAccuracy: 56.1%, Avg loss: 1.842560 \n\nEpoch 304\n-------------------------------\nloss: 2.376925 [  128/ 1020]\nloss: 2.424363 [  640/ 1020]\nValidation Error:\nAccuracy: 50.9%, Avg loss: 1.992207 \n\nTraining Error:\nAccuracy: 56.6%, Avg loss: 1.852923 \n\nEpoch 305\n-------------------------------\nloss: 2.379188 [  128/ 1020]\nloss: 2.381504 [  640/ 1020]\nValidation Error:\nAccuracy: 49.2%, Avg loss: 2.040428 \n\nTraining Error:\nAccuracy: 52.8%, Avg loss: 1.944907 \n\nEpoch 306\n-------------------------------\nloss: 2.390615 [  128/ 1020]\nloss: 2.044765 [  640/ 1020]\nValidation Error:\nAccuracy: 50.1%, Avg loss: 2.010884 \n\nTraining Error:\nAccuracy: 58.2%, Avg loss: 1.783174 \n\nEpoch 307\n-------------------------------\nloss: 2.457714 [  128/ 1020]\nloss: 2.266535 [  640/ 1020]\nValidation Error:\nAccuracy: 50.4%, Avg loss: 1.997741 \n\nTraining Error:\nAccuracy: 55.3%, Avg loss: 1.824796 \n\nEpoch 308\n-------------------------------\nloss: 2.259846 [  128/ 1020]\nloss: 2.605167 [  640/ 1020]\nValidation Error:\nAccuracy: 50.9%, Avg loss: 1.997581 \n\nTraining Error:\nAccuracy: 54.6%, Avg loss: 1.893268 \n\nEpoch 309\n-------------------------------\nloss: 2.151952 [  128/ 1020]\nloss: 2.359591 [  640/ 1020]\nValidation Error:\nAccuracy: 51.3%, Avg loss: 1.998220 \n\nTraining Error:\nAccuracy: 57.7%, Avg loss: 1.761969 \n\nEpoch 310\n-------------------------------\nloss: 2.494811 [  128/ 1020]\nloss: 2.468232 [  640/ 1020]\nValidation Error:\nAccuracy: 51.3%, Avg loss: 1.971067 \n\nTraining Error:\nAccuracy: 54.7%, Avg loss: 1.863002 \n\nEpoch 311\n-------------------------------\nloss: 2.108919 [  128/ 1020]\nloss: 2.425829 [  640/ 1020]\nValidation Error:\nAccuracy: 51.8%, Avg loss: 1.977659 \n\nTraining Error:\nAccuracy: 54.0%, Avg loss: 1.897608 \n\nEpoch 312\n-------------------------------\nloss: 2.392042 [  128/ 1020]\nloss: 2.434842 [  640/ 1020]\nValidation Error:\nAccuracy: 51.5%, Avg loss: 1.984730 \n\nTraining Error:\nAccuracy: 55.8%, Avg loss: 1.843623 \n\nEpoch 313\n-------------------------------\nloss: 2.537817 [  128/ 1020]\nloss: 2.348865 [  640/ 1020]\nValidation Error:\nAccuracy: 51.2%, Avg loss: 1.991781 \n\nTraining Error:\nAccuracy: 56.4%, Avg loss: 1.821685 \n\nEpoch 314\n-------------------------------\nloss: 2.432186 [  128/ 1020]\nloss: 2.464041 [  640/ 1020]\nValidation Error:\nAccuracy: 51.1%, Avg loss: 1.998211 \n\nTraining Error:\nAccuracy: 59.3%, Avg loss: 1.743643 \n\nEpoch 315\n-------------------------------\nloss: 2.326376 [  128/ 1020]\nloss: 1.966731 [  640/ 1020]\nValidation Error:\nAccuracy: 50.5%, Avg loss: 1.975848 \n\nTraining Error:\nAccuracy: 55.7%, Avg loss: 1.828534 \n\nEpoch 316\n-------------------------------\nloss: 2.268063 [  128/ 1020]\nloss: 2.415358 [  640/ 1020]\nValidation Error:\nAccuracy: 52.2%, Avg loss: 1.976852 \n\nTraining Error:\nAccuracy: 53.5%, Avg loss: 1.966900 \n\nEpoch 317\n-------------------------------\nloss: 2.307210 [  128/ 1020]\nloss: 2.527196 [  640/ 1020]\nValidation Error:\nAccuracy: 52.1%, Avg loss: 1.999641 \n\nTraining Error:\nAccuracy: 56.6%, Avg loss: 1.753919 \n\nEpoch 318\n-------------------------------\nloss: 2.374609 [  128/ 1020]\nloss: 2.476571 [  640/ 1020]\nValidation Error:\nAccuracy: 51.4%, Avg loss: 2.009672 \n\nTraining Error:\nAccuracy: 54.8%, Avg loss: 1.843036 \n\nEpoch 319\n-------------------------------\nloss: 2.168133 [  128/ 1020]\nloss: 2.193179 [  640/ 1020]\nValidation Error:\nAccuracy: 51.8%, Avg loss: 1.959431 \n\nTraining Error:\nAccuracy: 55.9%, Avg loss: 1.821021 \n\nEpoch 320\n-------------------------------\nloss: 2.144956 [  128/ 1020]\nloss: 2.531666 [  640/ 1020]\nValidation Error:\nAccuracy: 52.4%, Avg loss: 1.954132 \n\nTraining Error:\nAccuracy: 54.4%, Avg loss: 1.829238 \n\nEpoch 321\n-------------------------------\nloss: 2.282531 [  128/ 1020]\nloss: 2.287261 [  640/ 1020]\nValidation Error:\nAccuracy: 51.1%, Avg loss: 1.942390 \n\nTraining Error:\nAccuracy: 57.0%, Avg loss: 1.815387 \n\nEpoch 322\n-------------------------------\nloss: 2.339061 [  128/ 1020]\nloss: 2.454293 [  640/ 1020]\nValidation Error:\nAccuracy: 51.7%, Avg loss: 1.930410 \n\nTraining Error:\nAccuracy: 54.9%, Avg loss: 1.862250 \n\nEpoch 323\n-------------------------------\nloss: 2.272420 [  128/ 1020]\nloss: 2.563320 [  640/ 1020]\nValidation Error:\nAccuracy: 54.3%, Avg loss: 1.913833 \n\nTraining Error:\nAccuracy: 56.9%, Avg loss: 1.842418 \n\nEpoch 324\n-------------------------------\nloss: 2.285112 [  128/ 1020]\nloss: 2.608154 [  640/ 1020]\nValidation Error:\nAccuracy: 52.7%, Avg loss: 1.961814 \n\nTraining Error:\nAccuracy: 56.2%, Avg loss: 1.798685 \n\nEpoch 325\n-------------------------------\nloss: 2.366519 [  128/ 1020]\nloss: 2.620149 [  640/ 1020]\nValidation Error:\nAccuracy: 53.0%, Avg loss: 1.988607 \n\nTraining Error:\nAccuracy: 56.8%, Avg loss: 1.761175 \n\nEpoch 326\n-------------------------------\nloss: 2.358189 [  128/ 1020]\nloss: 2.321654 [  640/ 1020]\nValidation Error:\nAccuracy: 52.3%, Avg loss: 1.961334 \n\nTraining Error:\nAccuracy: 57.1%, Avg loss: 1.842144 \n\nEpoch 327\n-------------------------------\nloss: 2.355908 [  128/ 1020]\nloss: 2.365475 [  640/ 1020]\nValidation Error:\nAccuracy: 52.1%, Avg loss: 1.942764 \n\nTraining Error:\nAccuracy: 57.4%, Avg loss: 1.780297 \n\nEpoch 328\n-------------------------------\nloss: 2.544812 [  128/ 1020]\nloss: 2.293739 [  640/ 1020]\nValidation Error:\nAccuracy: 52.8%, Avg loss: 1.969820 \n\nTraining Error:\nAccuracy: 55.1%, Avg loss: 1.897684 \n\nEpoch 329\n-------------------------------\nloss: 2.087720 [  128/ 1020]\nloss: 2.269194 [  640/ 1020]\nValidation Error:\nAccuracy: 52.3%, Avg loss: 1.921314 \n\nTraining Error:\nAccuracy: 57.5%, Avg loss: 1.833125 \n\nEpoch 330\n-------------------------------\nloss: 2.133685 [  128/ 1020]\nloss: 2.274787 [  640/ 1020]\nValidation Error:\nAccuracy: 53.0%, Avg loss: 1.945202 \n\nTraining Error:\nAccuracy: 57.7%, Avg loss: 1.778474 \n\nEpoch 331\n-------------------------------\nloss: 2.574214 [  128/ 1020]\nloss: 2.350342 [  640/ 1020]\nValidation Error:\nAccuracy: 53.3%, Avg loss: 1.926324 \n\nTraining Error:\nAccuracy: 58.4%, Avg loss: 1.789831 \n\nEpoch 332\n-------------------------------\nloss: 2.172801 [  128/ 1020]\nloss: 2.457624 [  640/ 1020]\nValidation Error:\nAccuracy: 52.5%, Avg loss: 1.958737 \n\nTraining Error:\nAccuracy: 56.8%, Avg loss: 1.811031 \n\nEpoch 333\n-------------------------------\nloss: 2.144182 [  128/ 1020]\nloss: 2.271011 [  640/ 1020]\nValidation Error:\nAccuracy: 51.3%, Avg loss: 1.925132 \n\nTraining Error:\nAccuracy: 56.1%, Avg loss: 1.783553 \n\nEpoch 334\n-------------------------------\nloss: 2.033676 [  128/ 1020]\nloss: 2.037383 [  640/ 1020]\nValidation Error:\nAccuracy: 52.8%, Avg loss: 1.932794 \n\nTraining Error:\nAccuracy: 57.8%, Avg loss: 1.796960 \n\nEpoch 335\n-------------------------------\nloss: 2.070831 [  128/ 1020]\nloss: 2.508231 [  640/ 1020]\nValidation Error:\nAccuracy: 52.5%, Avg loss: 1.942301 \n\nTraining Error:\nAccuracy: 55.2%, Avg loss: 1.860302 \n\nEpoch 336\n-------------------------------\nloss: 2.194144 [  128/ 1020]\nloss: 2.356565 [  640/ 1020]\nValidation Error:\nAccuracy: 52.5%, Avg loss: 1.951707 \n\nTraining Error:\nAccuracy: 58.5%, Avg loss: 1.757035 \n\nEpoch 337\n-------------------------------\nloss: 2.434099 [  128/ 1020]\nloss: 2.509033 [  640/ 1020]\nValidation Error:\nAccuracy: 53.3%, Avg loss: 1.908945 \n\nTraining Error:\nAccuracy: 55.9%, Avg loss: 1.818208 \n\nEpoch 338\n-------------------------------\nloss: 2.331894 [  128/ 1020]\nloss: 2.186204 [  640/ 1020]\nValidation Error:\nAccuracy: 51.2%, Avg loss: 1.957017 \n\nTraining Error:\nAccuracy: 57.7%, Avg loss: 1.748890 \n\nEpoch 339\n-------------------------------\nloss: 2.327388 [  128/ 1020]\nloss: 2.340853 [  640/ 1020]\nValidation Error:\nAccuracy: 52.5%, Avg loss: 1.930757 \n\nTraining Error:\nAccuracy: 57.9%, Avg loss: 1.793471 \n\nEpoch 340\n-------------------------------\nloss: 2.105808 [  128/ 1020]\nloss: 2.268659 [  640/ 1020]\nValidation Error:\nAccuracy: 52.4%, Avg loss: 1.889171 \n\nTraining Error:\nAccuracy: 57.8%, Avg loss: 1.802726 \n\nEpoch 341\n-------------------------------\nloss: 2.531377 [  128/ 1020]\nloss: 2.307920 [  640/ 1020]\nValidation Error:\nAccuracy: 51.3%, Avg loss: 1.932647 \n\nTraining Error:\nAccuracy: 55.7%, Avg loss: 1.800826 \n\nEpoch 342\n-------------------------------\nloss: 2.247385 [  128/ 1020]\nloss: 2.205770 [  640/ 1020]\nValidation Error:\nAccuracy: 51.9%, Avg loss: 1.967609 \n\nTraining Error:\nAccuracy: 57.8%, Avg loss: 1.749817 \n\nEpoch 343\n-------------------------------\nloss: 2.153953 [  128/ 1020]\nloss: 2.215849 [  640/ 1020]\nValidation Error:\nAccuracy: 52.0%, Avg loss: 1.935773 \n\nTraining Error:\nAccuracy: 56.7%, Avg loss: 1.780413 \n\nEpoch 344\n-------------------------------\nloss: 2.367463 [  128/ 1020]\nloss: 2.310887 [  640/ 1020]\nValidation Error:\nAccuracy: 52.1%, Avg loss: 1.907185 \n\nTraining Error:\nAccuracy: 54.3%, Avg loss: 1.893137 \n\nEpoch 345\n-------------------------------\nloss: 2.293966 [  128/ 1020]\nloss: 2.526455 [  640/ 1020]\nValidation Error:\nAccuracy: 51.4%, Avg loss: 1.952583 \n\nTraining Error:\nAccuracy: 59.1%, Avg loss: 1.758184 \n\nEpoch 346\n-------------------------------\nloss: 2.058722 [  128/ 1020]\nloss: 2.334506 [  640/ 1020]\nValidation Error:\nAccuracy: 51.3%, Avg loss: 1.960693 \n\nTraining Error:\nAccuracy: 56.2%, Avg loss: 1.856291 \n\nEpoch 347\n-------------------------------\nloss: 2.230147 [  128/ 1020]\nloss: 2.018008 [  640/ 1020]\nValidation Error:\nAccuracy: 52.5%, Avg loss: 1.913433 \n\nTraining Error:\nAccuracy: 54.7%, Avg loss: 1.844508 \n\nEpoch 348\n-------------------------------\nloss: 2.468551 [  128/ 1020]\nloss: 2.543389 [  640/ 1020]\nValidation Error:\nAccuracy: 52.4%, Avg loss: 1.921672 \n\nTraining Error:\nAccuracy: 57.1%, Avg loss: 1.805626 \n\nEpoch 349\n-------------------------------\nloss: 2.369161 [  128/ 1020]\nloss: 2.628256 [  640/ 1020]\nValidation Error:\nAccuracy: 51.6%, Avg loss: 1.937676 \n\nTraining Error:\nAccuracy: 55.3%, Avg loss: 1.837270 \n\nEpoch 350\n-------------------------------\nloss: 2.055113 [  128/ 1020]\nloss: 2.165654 [  640/ 1020]\nValidation Error:\nAccuracy: 52.0%, Avg loss: 1.929595 \n\nTraining Error:\nAccuracy: 59.6%, Avg loss: 1.733652 \n\nEpoch 351\n-------------------------------\nloss: 2.096158 [  128/ 1020]\nloss: 1.997040 [  640/ 1020]\nValidation Error:\nAccuracy: 52.3%, Avg loss: 1.921565 \n\nTraining Error:\nAccuracy: 59.8%, Avg loss: 1.748614 \n\nEpoch 352\n-------------------------------\nloss: 1.872836 [  128/ 1020]\nloss: 2.271918 [  640/ 1020]\nValidation Error:\nAccuracy: 52.7%, Avg loss: 1.928785 \n\nTraining Error:\nAccuracy: 56.2%, Avg loss: 1.854711 \n\nEpoch 353\n-------------------------------\nloss: 2.431180 [  128/ 1020]\nloss: 2.327646 [  640/ 1020]\nValidation Error:\nAccuracy: 53.1%, Avg loss: 1.904377 \n\nTraining Error:\nAccuracy: 57.5%, Avg loss: 1.775805 \n\nEpoch 354\n-------------------------------\nloss: 2.349661 [  128/ 1020]\nloss: 2.307211 [  640/ 1020]\nValidation Error:\nAccuracy: 53.1%, Avg loss: 1.928035 \n\nTraining Error:\nAccuracy: 57.9%, Avg loss: 1.770246 \n\nEpoch 355\n-------------------------------\nloss: 2.251996 [  128/ 1020]\nloss: 2.348444 [  640/ 1020]\nValidation Error:\nAccuracy: 53.1%, Avg loss: 1.918098 \n\nTraining Error:\nAccuracy: 57.8%, Avg loss: 1.746065 \n\nEpoch 356\n-------------------------------\nloss: 2.500166 [  128/ 1020]\nloss: 2.410072 [  640/ 1020]\nValidation Error:\nAccuracy: 52.9%, Avg loss: 1.894186 \n\nTraining Error:\nAccuracy: 59.6%, Avg loss: 1.697199 \n\nEpoch 357\n-------------------------------\nloss: 2.226701 [  128/ 1020]\nloss: 2.269933 [  640/ 1020]\nValidation Error:\nAccuracy: 52.5%, Avg loss: 1.931335 \n\nTraining Error:\nAccuracy: 58.1%, Avg loss: 1.764384 \n\nEpoch 358\n-------------------------------\nloss: 2.132950 [  128/ 1020]\nloss: 2.231325 [  640/ 1020]\nValidation Error:\nAccuracy: 51.7%, Avg loss: 1.923567 \n\nTraining Error:\nAccuracy: 54.7%, Avg loss: 1.803986 \n\nEpoch 359\n-------------------------------\nloss: 1.980818 [  128/ 1020]\nloss: 2.227922 [  640/ 1020]\nValidation Error:\nAccuracy: 54.0%, Avg loss: 1.877409 \n\nTraining Error:\nAccuracy: 56.4%, Avg loss: 1.823783 \n\nEpoch 360\n-------------------------------\nloss: 2.041264 [  128/ 1020]\nloss: 2.148092 [  640/ 1020]\nValidation Error:\nAccuracy: 53.8%, Avg loss: 1.880303 \n\nTraining Error:\nAccuracy: 56.2%, Avg loss: 1.808452 \n\nDone!\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Testing error:\")\n",
    "test(test_dataloader, model, [], [])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T17:37:10.029795Z",
     "iopub.execute_input": "2023-05-07T17:37:10.030250Z",
     "iopub.status.idle": "2023-05-07T17:37:51.627961Z",
     "shell.execute_reply.started": "2023-05-07T17:37:10.030212Z",
     "shell.execute_reply": "2023-05-07T17:37:51.626994Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": "Testing error:\nAccuracy: 50.3%, Avg loss: 2.066017 \n\n",
     "output_type": "stream"
    },
    {
     "execution_count": 36,
     "output_type": "execute_result",
     "data": {
      "text/plain": "2.0660165262465573"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sns.set()\n",
    "f, ax = plt.subplots(2, 1)\n",
    "plt.plot()\n",
    "ax[0].plot(val_accuracy, label=\"Validation\")\n",
    "ax[0].plot(train_accuracy, label=\"Training\")\n",
    "ax[0].set_ylim(0, 100)\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy (%)\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(val_losses, label=\"Validation\")\n",
    "ax[1].plot(train_losses, label=\"Training\")\n",
    "ax[1].set_ylim(0, 5)\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Loss\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T17:34:24.874641Z",
     "iopub.execute_input": "2023-05-07T17:34:24.875060Z",
     "iopub.status.idle": "2023-05-07T17:34:25.345736Z",
     "shell.execute_reply.started": "2023-05-07T17:34:24.875031Z",
     "shell.execute_reply": "2023-05-07T17:34:25.344869Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model, \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-07T17:34:27.729338Z",
     "iopub.execute_input": "2023-05-07T17:34:27.729684Z",
     "iopub.status.idle": "2023-05-07T17:34:27.923126Z",
     "shell.execute_reply.started": "2023-05-07T17:34:27.729658Z",
     "shell.execute_reply": "2023-05-07T17:34:27.921979Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": "Saved PyTorch Model State to model.pth\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
